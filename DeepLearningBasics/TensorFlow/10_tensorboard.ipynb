{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQuBBbdqleLodBAP8Ighgc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dchlseo/DataScienceProjects/blob/main/DeepLearningBasics/TensorFlow/10_tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "- https://www.tensorflow.org/tensorboard?hl=ko\n",
        "- [tensorboard in google colab](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb)"
      ],
      "metadata": {
        "id": "qIJ6sc1d_0QP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PRbdnlwV_t3z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7777)\n",
        "tf.random.set_seed(7777)"
      ],
      "metadata": {
        "id": "wb1m3nC6_3Fc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cifar10DataLoader():\n",
        "    def __init__(self):\n",
        "        # data load\n",
        "        (self.train_x, self.train_y), \\\n",
        "            (self.test_x, self.test_y) = tf.keras.datasets.cifar10.load_data()\n",
        "        self.input_shape = self.train_x.shape[1:]\n",
        "\n",
        "    def scale(self, x):\n",
        "\n",
        "        return (x / 255.0).astype(np.float32)\n",
        "\n",
        "    def preprocess_dataset(self, dataset):\n",
        "\n",
        "        (feature, target) = dataset\n",
        "\n",
        "        # scaling #\n",
        "        scaled_x = np.array([self.scale(x) for x in feature])\n",
        "\n",
        "        # label encoding #\n",
        "        ohe_y = np.array([tf.keras.utils.to_categorical(\n",
        "            y, num_classes=10) for y in target])\n",
        "\n",
        "        return scaled_x, ohe_y.squeeze(1)\n",
        "\n",
        "    def get_train_dataset(self):\n",
        "        return self.preprocess_dataset((self.train_x, self.train_y))\n",
        "\n",
        "    def get_test_dataset(self):\n",
        "        return self.preprocess_dataset((self.test_x, self.test_y))\n",
        "\n",
        "cifar10_loader = Cifar10DataLoader()\n",
        "train_x, train_y = cifar10_loader.get_train_dataset()\n",
        "\n",
        "print(train_x.shape, train_x.dtype)\n",
        "print(train_y.shape, train_y.dtype)\n",
        "\n",
        "test_x, test_y = cifar10_loader.get_test_dataset()\n",
        "\n",
        "print(test_x.shape, test_x.dtype)\n",
        "print(test_y.shape, test_y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQnet2aU_4SD",
        "outputId": "7dc34fd2-2a87-4ffb-fd5a-e3a0590f8a39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) float32\n",
            "(50000, 10) float32\n",
            "(10000, 32, 32, 3) float32\n",
            "(10000, 10) float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Add\n",
        "\n",
        "def build_resnet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    net = Conv2D(16, kernel_size=3, strides=2,\n",
        "                 padding='same', activation='relu')(inputs)\n",
        "    net = MaxPool2D()(net)\n",
        "\n",
        "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
        "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1)\n",
        "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
        "\n",
        "    net1_1 = Conv2D(32, kernel_size=1, padding='same')(net)\n",
        "    net = Add()([net1_1, net3])\n",
        "\n",
        "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
        "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1)\n",
        "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
        "\n",
        "    net = Add()([net, net3])\n",
        "\n",
        "    net = MaxPool2D()(net)\n",
        "\n",
        "    net = Flatten()(net)\n",
        "    net = Dense(10, activation=\"softmax\")(net)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=net, name='resnet')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_resnet((32, 32, 3))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmlctXtg_5fP",
        "outputId": "30bc6006-450e-4d2d-cda5-b552a289d1cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 16, 16, 16)           448       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 8, 8, 16)             0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 32)             544       ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 32)             9248      ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 32)             544       ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 32)             1056      ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 8, 8, 32)             0         ['conv2d_4[0][0]',            \n",
            "                                                                     'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 32)             1056      ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 32)             9248      ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 8, 8, 32)             1056      ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 8, 8, 32)             0         ['add[0][0]',                 \n",
            "                                                                     'conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 32)             0         ['add_1[0][0]']               \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 512)                  0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   5130      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28330 (110.66 KB)\n",
            "Trainable params: 28330 (110.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.03\n",
        "opt = tf.keras.optimizers.Adam(learning_rate)\n",
        "loss = tf.keras.losses.binary_crossentropy\n",
        "\n",
        "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZwoqB2t-BhOm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logs using callbacks"
      ],
      "metadata": {
        "id": "H19QtJX8Ci1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "log_dir = os.path.join(\"logs/fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "metadata": {
        "id": "s811K9AZAKAE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "uy8wOu9tBK4V",
        "outputId": "3c17535e-c78d-42aa-b745-e31aeb2e80bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'logs/fit20231106-050455'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "4_mqb11X_7F5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=train_x,\n",
        "          y=train_y,\n",
        "          epochs=5,\n",
        "          validation_data=(test_x, test_y),\n",
        "          callbacks=[tb_callback]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWcO9J4WBTTV",
        "outputId": "e6024bcd-347a-483d-b760-49538129409c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 34s 20ms/step - loss: 0.2782 - accuracy: 0.3422 - val_loss: 0.2765 - val_accuracy: 0.3340\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2702 - accuracy: 0.3661 - val_loss: 0.2638 - val_accuracy: 0.4055\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.2706 - accuracy: 0.3657 - val_loss: 0.2753 - val_accuracy: 0.3581\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2698 - accuracy: 0.3702 - val_loss: 0.2624 - val_accuracy: 0.3964\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.2700 - accuracy: 0.3735 - val_loss: 0.3019 - val_accuracy: 0.3175\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b93a1719150>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JY9II4fnDVAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv5TohWPDNh5",
        "outputId": "406103a9-7bfc-4070-a91f-544f1f1ce610"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir log_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBvK7YejDV41",
        "outputId": "534bb3fc-008d-4803-e0f3-7f53e744dc33"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-06 05:16:55.964854: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-06 05:16:55.964930: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-06 05:16:55.964968: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-06 05:16:57.243571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Address already in use\n",
            "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard import notebook\n",
        "notebook.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXT805xVCni6",
        "outputId": "ca5d2a94-1964-4e30-e376-2188fa3a328f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Known TensorBoard instances:\n",
            "  - port 6006: logdir log_dir (started 0:00:34 ago; pid 4228)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using tf.summary"
      ],
      "metadata": {
        "id": "g9U5szF-Dc3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.categorical_crossentropy\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y) :\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(y, pred)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(y, pred)\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y) :\n",
        "\n",
        "    pred = model(x)\n",
        "    loss = loss_fn(y, pred)\n",
        "\n",
        "    test_loss(loss)\n",
        "    test_accuracy(y, pred)"
      ],
      "metadata": {
        "id": "0pRidk0AEGYw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'"
      ],
      "metadata": {
        "id": "c8C1umAJEJYQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "metadata": {
        "id": "TI1vmx-pEMwy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "num_of_batch_train = train_x.shape[0] // batch_size\n",
        "num_of_batch_test = test_x.shape[0] // batch_size\n",
        "\n",
        "for epoch in range(5):\n",
        "\n",
        "    for i in range(num_of_batch_train):\n",
        "        idx = i * batch_size\n",
        "        x, y = train_x[idx:idx+batch_size], train_y[idx:idx+batch_size]\n",
        "        train_step(x, y)\n",
        "        print(\"\\r Train : {} / {}\".format(i, num_of_batch_train), end='\\r')\n",
        "\n",
        "\n",
        "    for i in range(num_of_batch_test):\n",
        "        idx = i * batch_size\n",
        "        x, y = test_x[idx:idx+batch_size], test_y[idx:idx+batch_size]\n",
        "        test_step(x, y)\n",
        "        print(\"\\r Test : {} / {}\".format(i, num_of_batch_test), end='\\r')\n",
        "\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('acc', train_accuracy.result(), step=epoch)\n",
        "\n",
        "    with test_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('acc', test_accuracy.result(), step=epoch)\n",
        "\n",
        "    fmt = 'epoch {} loss: {}, accuracy: {}, test_loss: {}, test_acc: {}'\n",
        "    print(fmt.format(epoch+1,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result(),\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result()\n",
        "                    )\n",
        "         )\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qrD-hVTEN3W",
        "outputId": "459488d2-c569-4370-f6fb-e7de59294f80"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 loss: 2.7219741344451904, accuracy: 0.09879161417484283, test_loss: 2.3220443725585938, test_acc: 0.10006009787321091\n",
            "epoch 2 loss: 2.314493179321289, accuracy: 0.0981714129447937, test_loss: 2.3142189979553223, test_acc: 0.10006009787321091\n",
            "epoch 3 loss: 2.310041666030884, accuracy: 0.09805137664079666, test_loss: 2.3195512294769287, test_acc: 0.10006009787321091\n",
            "epoch 4 loss: 2.3103299140930176, accuracy: 0.09893165528774261, test_loss: 2.32029390335083, test_acc: 0.09985977411270142\n",
            "epoch 5 loss: 2.3151516914367676, accuracy: 0.10065221041440964, test_loss: 2.32436466217041, test_acc: 0.09985977411270142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir logs/gradient_tape --load_fast=false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L2EYBFnEPdn",
        "outputId": "9a46905f-f8b6-4633-973f-534255ab051c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-06 05:20:41.657048: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-06 05:20:41.657111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-06 05:20:41.657147: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-06 05:20:42.845825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Address already in use\n",
            "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"logs/train_data/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "for i in np.random.randint(10000, size=10):\n",
        "    img = train_x[i:i+1]\n",
        "    with file_writer.as_default():\n",
        "        tf.summary.image(\"Training Sample data : {}\".format(i), img, step=0)"
      ],
      "metadata": {
        "id": "UE531tYbEQ8E"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir logs/train_data"
      ],
      "metadata": {
        "id": "_hfIUdRhFLbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LambdaCallback을 사용하여 Tensorboard에 Confusion Matrix 기록"
      ],
      "metadata": {
        "id": "GLP_sZg4FTvX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cVj9DpwXFXcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_to_image(figure):\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "\n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    threshold = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure\n",
        "\n",
        "logdir = \"logs/fit/cm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "test_images = test_x[:100]\n",
        "test_labels = np.argmax(test_y[:100], axis=1)\n",
        "\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "    test_pred_raw = model.predict(test_images)\n",
        "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "    classes = np.arange(10)\n",
        "    cm = confusion_matrix(test_labels, test_pred, labels=classes)\n",
        "\n",
        "    figure = plot_confusion_matrix(cm, class_names=classes)\n",
        "    cm_image = plot_to_image(figure)\n",
        "\n",
        "    with file_writer_cm.as_default():\n",
        "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
      ],
      "metadata": {
        "id": "L1y0-ZPtFOMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "5ajxJERKFYfM",
        "outputId": "e7325f97-ccd4-47fc-f3fc-61111a32f05c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7de0e22c320b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_confusion_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'log_confusion_matrix' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=train_x,\n",
        "          y=train_y,\n",
        "          epochs=5,\n",
        "          batch_size=32,\n",
        "          validation_data=(test_x, test_y),\n",
        "          callbacks=[tensorboard_callback, cm_callback])"
      ],
      "metadata": {
        "id": "llS8uhyUFZUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "xyPBwx1LFbhu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}